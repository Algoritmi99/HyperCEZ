{
  "alt0": {
    "model": {
      "num_blocks": 1,
      "num_channels": 64,
      "reduced_channels": 16,
      "fc_layers": [
        32
      ],
      "down_sample": true,
      "state_norm": false,
      "value_prefix": true,
      "init_zero": true,
      "action_embedding": true,
      "action_embedding_dim": 16,
      "value_policy_detach": false,
      "reward_support": {
        "range": [
          -300,
          300
        ],
        "scale": 1,
        "env": "Atari",
        "bins": 51,
        "type": "support"
      },
      "value_support": {
        "range": [
          -300,
          300
        ],
        "scale": 1,
        "env": "Atari",
        "bins": 51,
        "type": "support"
      },
      "lstm_hidden_size": 512,
      "projection_layers": [
        1024,
        1024
      ],
      "projection_head_layers": [
        256,
        1024
      ]
    },
    "train": {
      "load_model_path": "",
      "batch_size": 256,
      "training_steps": 100000,
      "offline_training_steps": 20000,
      "start_transitions": 2000,
      "eval_n_episode": 10,
      "eval_interval": 10000,
      "self_play_update_interval": 100,
      "reanalyze_update_interval": 200,
      "save_ckpt_interval": 10000,
      "mini_batch_size": 256,
      "reanalyze_ratio": 1.0,
      "reward_loss_coeff": 1.0,
      "value_loss_coeff": 0.5,
      "policy_loss_coeff": 1.0,
      "consistency_coeff": 5.0,
      "decorrelation_coeff": 0.01,
      "off_diag_coeff": 0.005,
      "entropy_coeff": 0.005,
      "max_grad_norm": 5,
      "change_temperature": true,
      "periodic_reset": false,
      "value_reanalyze": false,
      "path_consistency": false,
      "use_decorrelation": false,
      "value_policy_detach": false,
      "optimal_Q": false,
      "v_num": 1,
      "value_target": "mixed",
      "use_IQL": false,
      "IQL_weight": 0.7,
      "start_use_mix_training_steps": 30000.0,
      "mixed_value_threshold": 5000.0
    },
    "mcts_lang": "python"
  },
  "alt1": {
    "model": {
      "noisy_net": false,
      "action_embedding": true,
      "action_embedding_dim": 16,
      "block_type": "resnet",
      "down_sample": true,
      "state_norm": false,
      "value_prefix": false,
      "value_target": "bootstrapped",
      "GAE_max_steps": 15,
      "dynamic_type": null,
      "init_zero": true,
      "num_blocks": 1,
      "num_channels": 64,
      "reduced_channels": 16,
      "projection_layers": [
        1024,
        1024
      ],
      "projection_head_layers": [
        256,
        1024
      ],
      "fc_layers": [
        32
      ],
      "lstm_hidden_size": 512,
      "lstm_horizon_len": 5,
      "value_ensumble": 1,
      "policy_distribution": "squashed_gaussian",
      "policy_loss_type": "reanalyze",
      "policy_action_num": 4,
      "random_action_num": 12,
      "random_type": "std",
      "reward_support": {
        "range": [
          -2,
          2
        ],
        "scale": 0.01,
        "env": "DMC",
        "bins": 51,
        "type": "support"
      },
      "value_support": {
        "range": [
          -299,
          299
        ],
        "scale": 0.5,
        "env": "DMC",
        "bins": 51,
        "type": "support"
      }
    },
    "train": {
      "load_model_path": "",
      "batch_size": 256,
      "training_steps": 200000,
      "offline_training_steps": 20000,
      "start_transitions": 2000,
      "eval_n_episode": 10,
      "eval_interval": 5000,
      "self_play_update_interval": 100,
      "reanalyze_update_interval": 200,
      "save_ckpt_interval": 10000,
      "mini_batch_size": 256,
      "reanalyze_ratio": 1.0,
      "reward_loss_coeff": 1.0,
      "value_loss_coeff": 0.5,
      "policy_loss_coeff": 1.0,
      "consistency_coeff": 2.0,
      "decorrelation_coeff": 0.01,
      "off_diag_coeff": 0.005,
      "entropy_coeff": 0.005,
      "max_grad_norm": 5,
      "change_temperature": true,
      "periodic_reset": false,
      "value_reanalyze": false,
      "path_consistency": false,
      "use_decorrelation": false,
      "value_policy_detach": false,
      "optimal_Q": false,
      "v_num": 1,
      "value_target": "mixed",
      "use_IQL": false,
      "IQL_weight": 0.5,
      "start_use_mix_training_steps": 40000.0,
      "mixed_value_threshold": 20000.0
    },
    "mcts_lang": "python"

  },
  "alt2": {
    "model": {
      "noisy_net": false,
      "action_embedding": true,
      "block_type": "resnet",
      "down_sample": true,
      "state_norm": false,
      "value_prefix": false,
      "value_target": "bootstrapped",
      "GAE_max_steps": 15,
      "dynamic_type": null,
      "init_zero": true,
      "use_bn": true,
      "use_p_norm": false,
      "num_blocks": 2,
      "hidden_shape": 128,
      "rep_net_shape": 256,
      "dyn_shape": 256,
      "act_embed_shape": 64,
      "rew_net_shape": [
        256,
        256
      ],
      "val_net_shape": [
        256,
        256
      ],
      "pi_net_shape": [
        256,
        256
      ],
      "proj_hid_shape": 512,
      "pred_hid_shape": 512,
      "proj_shape": 128,
      "pred_shape": 128,
      "fc_layers": [
        32
      ],
      "lstm_hidden_size": 512,
      "lstm_horizon_len": 5,
      "value_ensumble": 1,
      "policy_distribution": "squashed_gaussian",
      "policy_loss_type": "reanalyze",
      "policy_action_num": 4,
      "random_action_num": 12,
      "random_type": "std",
      "reward_support": {
        "range": [
          -2,
          2
        ],
        "scale": 0.01,
        "env": "DMC",
        "bins": 51,
        "type": "support"
      },
      "value_support": {
        "range": [
          -299,
          299
        ],
        "scale": 0.5,
        "env": "DMC",
        "bins": 51,
        "type": "support"
      }
    },
    "train": {
      "load_model_path": "",
      "batch_size": 256,
      "training_steps": 100000,
      "offline_training_steps": 20000,
      "start_transitions": 2000,
      "eval_n_episode": 10,
      "eval_interval": 5000,
      "self_play_update_interval": 100,
      "reanalyze_update_interval": 200,
      "save_ckpt_interval": 10000,
      "mini_batch_size": 256,
      "reanalyze_ratio": 1.0,
      "reward_loss_coeff": 1.0,
      "value_loss_coeff": 0.5,
      "policy_loss_coeff": 1.0,
      "consistency_coeff": 2.0,
      "decorrelation_coeff": 0.01,
      "off_diag_coeff": 0.005,
      "entropy_coeff": 0.05,
      "max_grad_norm": 5,
      "change_temperature": true,
      "periodic_reset": false,
      "value_reanalyze": false,
      "path_consistency": false,
      "use_decorrelation": false,
      "value_policy_detach": false,
      "optimal_Q": false,
      "v_num": 1,
      "value_target": "mixed",
      "use_IQL": false,
      "IQL_weight": 0.5,
      "start_use_mix_training_steps": 40000.0,
      "mixed_value_threshold": 20000.0
    },
    "mcts_lang": "python"
  }
}